{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMt6ok+6Q7d6cFKkjCqRbv0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GauravSingh3822/YoloV_5/blob/main/YoloV_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U45DbzFJVGvh",
        "outputId": "69eb71cb-6bf5-487a-e627-f646bba857f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16824, done.\u001b[K\n",
            "remote: Total 16824 (delta 0), reused 0 (delta 0), pack-reused 16824\u001b[K\n",
            "Receiving objects: 100% (16824/16824), 15.54 MiB | 14.96 MiB/s, done.\n",
            "Resolving deltas: 100% (11538/11538), done.\n",
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "# clone YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5.git # clone repo\n",
        "%cd yolov5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependencies as necessary\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "# from utils.google_utils import gdrive_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_dbvttHW412",
        "outputId": "77c7de71-d82e-45e4-ab26-3e857792552c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.6/825.6 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSetup complete. Using torch 2.2.1+cu121 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export code snippet and paste here\n",
        "%cd /content\n",
        "!curl -L \"https://app.roboflow.com/ds/87xlDYwZRa?key=9AGS5pPZrx\" > SKU.zip; unzip SKU.zip; rm SKU.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKJU66UWW443",
        "outputId": "89995731-2dc7-4157-ffef-7626b96da56f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   910  100   910    0     0   2590      0 --:--:-- --:--:-- --:--:--  2592\n",
            "100 1005k  100 1005k    0     0  1161k      0 --:--:-- --:--:-- --:--:-- 2317k\n",
            "Archive:  SKU.zip\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            " extracting: data.yaml               \n",
            "   creating: test/\n",
            "   creating: test/images/\n",
            " extracting: test/images/IMG-20230124-WA0002_jpg.rf.1c04adc84905ad5b4413d19e9de7fa59.jpg  \n",
            " extracting: test/images/IMG-20230124-WA0007_jpg.rf.257e1b864e1773264e3fecf7b1e0adc4.jpg  \n",
            " extracting: test/images/IMG-20230124-WA0009_jpg.rf.cffa4aee28d23081feaa0d8f83299728.jpg  \n",
            "   creating: test/labels/\n",
            " extracting: test/labels/IMG-20230124-WA0002_jpg.rf.1c04adc84905ad5b4413d19e9de7fa59.txt  \n",
            " extracting: test/labels/IMG-20230124-WA0007_jpg.rf.257e1b864e1773264e3fecf7b1e0adc4.txt  \n",
            " extracting: test/labels/IMG-20230124-WA0009_jpg.rf.cffa4aee28d23081feaa0d8f83299728.txt  \n",
            "   creating: train/\n",
            "   creating: train/images/\n",
            " extracting: train/images/IMG-20230124-WA0000_jpg.rf.b08d8d5e630ff37e6ab6c111907c02bd.jpg  \n",
            " extracting: train/images/IMG-20230124-WA0004_jpg.rf.9fea464f8ce7069668c4f890477a1735.jpg  \n",
            " extracting: train/images/IMG-20230124-WA0005_jpg.rf.9c80678d5767b5d105f6fc9a06a7f945.jpg  \n",
            " extracting: train/images/IMG-20230124-WA0006_jpg.rf.48680a78348216789ad794fcea728753.jpg  \n",
            " extracting: train/images/IMG-20230124-WA0008_jpg.rf.faa36b47b5af57fd2f4a86147fa9b3b0.jpg  \n",
            " extracting: train/images/IMG-20230124-WA0010_jpg.rf.e76dd66bd2403cc2fabad1a7e67e8a98.jpg  \n",
            " extracting: train/images/IMG-20230124-WA0011_jpg.rf.334c7d80eaa1610b0f6628de213c4c26.jpg  \n",
            " extracting: train/images/IMG-20230124-WA0013_jpg.rf.f745857335fa7d2d7786d2cc54ce1e0a.jpg  \n",
            "   creating: train/labels/\n",
            " extracting: train/labels/IMG-20230124-WA0000_jpg.rf.b08d8d5e630ff37e6ab6c111907c02bd.txt  \n",
            " extracting: train/labels/IMG-20230124-WA0004_jpg.rf.9fea464f8ce7069668c4f890477a1735.txt  \n",
            " extracting: train/labels/IMG-20230124-WA0005_jpg.rf.9c80678d5767b5d105f6fc9a06a7f945.txt  \n",
            " extracting: train/labels/IMG-20230124-WA0006_jpg.rf.48680a78348216789ad794fcea728753.txt  \n",
            " extracting: train/labels/IMG-20230124-WA0008_jpg.rf.faa36b47b5af57fd2f4a86147fa9b3b0.txt  \n",
            " extracting: train/labels/IMG-20230124-WA0010_jpg.rf.e76dd66bd2403cc2fabad1a7e67e8a98.txt  \n",
            " extracting: train/labels/IMG-20230124-WA0011_jpg.rf.334c7d80eaa1610b0f6628de213c4c26.txt  \n",
            " extracting: train/labels/IMG-20230124-WA0013_jpg.rf.f745857335fa7d2d7786d2cc54ce1e0a.txt  \n",
            "   creating: valid/\n",
            "   creating: valid/images/\n",
            " extracting: valid/images/IMG-20230124-WA0001_jpg.rf.c89784b82d1e82985adb8c1274f5de9e.jpg  \n",
            " extracting: valid/images/IMG-20230124-WA0003_jpg.rf.438a171795ebd23765442b63db2f61fd.jpg  \n",
            "   creating: valid/labels/\n",
            " extracting: valid/labels/IMG-20230124-WA0001_jpg.rf.c89784b82d1e82985adb8c1274f5de9e.txt  \n",
            " extracting: valid/labels/IMG-20230124-WA0003_jpg.rf.438a171795ebd23765442b63db2f61fd.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the YAML file  we're loading into this notebook with our data\n",
        "%cat data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWkHYfJUW48L",
        "outputId": "a2bdfa27-6de0-4fe7-b4b1-a8655e6d3ccc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 3\n",
            "names: ['Apple', 'Peach', 'Pineapple']\n",
            "\n",
            "roboflow:\n",
            "  workspace: physics-wallah-skills\n",
            "  project: beverage-detection\n",
            "  version: 1\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/physics-wallah-skills/beverage-detection/dataset/1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Model Configuration and Architecture\n",
        "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n",
        "\n",
        "You do not need to edit these cells, but you may."
      ],
      "metadata": {
        "id": "8iJx-zoNY1Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "with open(\"data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "metadata": {
        "id": "gXKLEYWmY0Pi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XlC86V0QY0bl",
        "outputId": "a255e821-c950-4407-e05a-be5ba84c838a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the model configuration we will use\n",
        "%cat /content/yolov5/models/yolov5s.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2oaPTCSY0du",
        "outputId": "e51f8fb1-cccb-488d-f0dd-34428e7ebd0e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Ultralytics YOLOv5 🚀, AGPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80 # number of classes\n",
            "depth_multiple: 0.33 # model depth multiple\n",
            "width_multiple: 0.50 # layer channel multiple\n",
            "anchors:\n",
            "  - [10, 13, 16, 30, 33, 23] # P3/8\n",
            "  - [30, 61, 62, 45, 59, 119] # P4/16\n",
            "  - [116, 90, 156, 198, 373, 326] # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [\n",
            "    [-1, 1, Conv, [64, 6, 2, 2]], # 0-P1/2\n",
            "    [-1, 1, Conv, [128, 3, 2]], # 1-P2/4\n",
            "    [-1, 3, C3, [128]],\n",
            "    [-1, 1, Conv, [256, 3, 2]], # 3-P3/8\n",
            "    [-1, 6, C3, [256]],\n",
            "    [-1, 1, Conv, [512, 3, 2]], # 5-P4/16\n",
            "    [-1, 9, C3, [512]],\n",
            "    [-1, 1, Conv, [1024, 3, 2]], # 7-P5/32\n",
            "    [-1, 3, C3, [1024]],\n",
            "    [-1, 1, SPPF, [1024, 5]], # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head: [\n",
            "    [-1, 1, Conv, [512, 1, 1]],\n",
            "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
            "    [[-1, 6], 1, Concat, [1]], # cat backbone P4\n",
            "    [-1, 3, C3, [512, False]], # 13\n",
            "\n",
            "    [-1, 1, Conv, [256, 1, 1]],\n",
            "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
            "    [[-1, 4], 1, Concat, [1]], # cat backbone P3\n",
            "    [-1, 3, C3, [256, False]], # 17 (P3/8-small)\n",
            "\n",
            "    [-1, 1, Conv, [256, 3, 2]],\n",
            "    [[-1, 14], 1, Concat, [1]], # cat head P4\n",
            "    [-1, 3, C3, [512, False]], # 20 (P4/16-medium)\n",
            "\n",
            "    [-1, 1, Conv, [512, 3, 2]],\n",
            "    [[-1, 10], 1, Concat, [1]], # cat head P5\n",
            "    [-1, 3, C3, [1024, False]], # 23 (P5/32-large)\n",
            "\n",
            "    [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "metadata": {
        "id": "EQJJO_MOY0hC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9gF_i2msZyiB",
        "outputId": "cb3a9abb-893e-4c0a-b3a1-495e54e4d992"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 2  # model depth multiple\n",
        "width_multiple: 1  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "metadata": {
        "id": "bOySu0ExZylO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the model configuration we will use\n",
        "%cat /content/yolov5/models/custom_yolov5s.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrxme4iTZyoA",
        "outputId": "60a48d23-c543-4866-dad5-df4cbba2ff5c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# parameters\n",
            "nc: 3  # number of classes\n",
            "depth_multiple: 2  # model depth multiple\n",
            "width_multiple: 1  # layer channel multiple\n",
            "\n",
            "# anchors\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, BottleneckCSP, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 9, BottleneckCSP, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, BottleneckCSP, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
            "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Custom YOLOv5 Detector\n",
        "Next, we'll fire off training!\n",
        "Here, we are able to pass a number of arguments:\n",
        "\n",
        "img: define input image size\n",
        "batch: determine batch size\n",
        "epochs: define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "data: set the path to our yaml file\n",
        "cfg: specify our model configuration\n",
        "weights: specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive folder)\n",
        "name: result names\n",
        "nosave: only save the final checkpoint\n",
        "cache: cache images for faster training"
      ],
      "metadata": {
        "id": "H-5KIn6KaTFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 640 --batch 5 --epochs 20 --data '../data.yaml' --cfg ./models/custom_yolov5s.yaml --weights 'yolov5s.pt' --name yolov5s_results  --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtdMOw_pZyqv",
        "outputId": "dfcfa6df-297c-4352-ff26-399178b952ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "2024-07-28 13:11:35.725991: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-28 13:11:35.726042: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-28 13:11:35.823589: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/custom_yolov5s.yaml, data=../data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=5, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-348-g6deb2d75 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 21.6MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 189MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  6    284800  models.common.BottleneckCSP             [128, 128, 6]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1 18   3107072  models.common.BottleneckCSP             [256, 256, 18]                \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1 18  12407296  models.common.BottleneckCSP             [512, 512, 18]                \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  1   2624512  models.common.SPP                       [1024, 1024, [5, 9, 13]]      \n",
            "  9                -1  6  18105344  models.common.BottleneckCSP             [1024, 1024, 6, False]        \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  6   4792832  models.common.BottleneckCSP             [1024, 512, 6, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  6   1200384  models.common.BottleneckCSP             [512, 256, 6, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  6   4530688  models.common.BottleneckCSP             [512, 512, 6, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  6  18105344  models.common.BottleneckCSP             [1024, 1024, 6, False]        \n",
            " 24      [17, 20, 23]  1     43080  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "custom_YOLOv5s summary: 653 layers, 75086664 parameters, 75086664 gradients\n",
            "\n",
            "Transferred 38/1089 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 179 weight(decay=0.0), 190 weight(decay=0.0005078125), 182 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels... 8 images, 0 backgrounds, 0 corrupt: 100% 8/8 [00:00<00:00, 292.32it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 8/8 [00:00<00:00, 183.25it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/valid/labels... 2 images, 0 backgrounds, 0 corrupt: 100% 2/2 [00:00<00:00, 142.05it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 2/2 [00:00<00:00, 96.98it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.61 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/yolov5s_results/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5s_results\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/19      5.22G     0.1097    0.06027    0.03766         27        640: 100% 2/2 [00:08<00:00,  4.11s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.34s/it]\n",
            "                   all          2         12    0.00316       0.05    0.00174   0.000523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/19      5.22G     0.1097    0.07466    0.03847         35        640: 100% 2/2 [00:00<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.42it/s]\n",
            "                   all          2         12    0.00316       0.05    0.00174   0.000523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/19      5.22G      0.116    0.06551    0.03874         17        640: 100% 2/2 [00:00<00:00,  3.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.94it/s]\n",
            "                   all          2         12    0.00316       0.05    0.00174   0.000523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/19      5.25G     0.1091    0.04558    0.03784         15        640: 100% 2/2 [00:00<00:00,  3.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.55it/s]\n",
            "                   all          2         12    0.00316       0.05    0.00174   0.000523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-UKXHl3PZyuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Custom YOLOv5 Detector Performance\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the --name flag when we train. In our case, we named this yolov5s_results. (If given no name, it defaults to results.txt.) The results file is plotted as a png after training completes.\n",
        "\n",
        "Note from Glenn: Partially completed results.txt files can be plotted with from utils.utils import plot_results; plot_results()"
      ],
      "metadata": {
        "id": "8wpd1eB1bK4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "pSf_EjarbLVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "_UYu_li9bLYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can also output some older school graphs if the tensor board isn't working for whatever reason...\n",
        "from utils.plots import plot_results  # plot results.txt as results.png\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png"
      ],
      "metadata": {
        "id": "uOttKAzMbLac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curious? Visualize Our Training Data with Labels\n",
        "After training starts, view train*.jpg images to see training images, labels and augmentation effects.\n",
        "\n",
        "Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher and first featured in"
      ],
      "metadata": {
        "id": "KqbUMynNbsmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first, display our ground truth data\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/val_batch0_labels.jpg', width=900)"
      ],
      "metadata": {
        "id": "akmFs11ubLb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print out an augmented training example\n",
        "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)"
      ],
      "metadata": {
        "id": "4t3_xUHpbLfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Inference With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of test/images folder downloaded from Roboflow."
      ],
      "metadata": {
        "id": "1DjXb0_5cHAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trained weights are saved by default in our weights folder\n",
        "%ls runs/"
      ],
      "metadata": {
        "id": "4qy0B1nbbJ_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls runs/train/yolov5s_results/weights"
      ],
      "metadata": {
        "id": "WQiZsfcEcJ_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
        "# use the best weights!\n",
        "%cd /content/yolov5/\n",
        "!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 640 --conf 0.0005 --source ../test/images"
      ],
      "metadata": {
        "id": "vDQiai0ccKB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cp /content/yolov5/runs/train/yolov5s_results/weights/best.pt /content/gdrive/MyDrive/Research/SKUKeep/model"
      ],
      "metadata": {
        "id": "SsXl1h-GcKEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display inference on ALL test images\n",
        "#this looks much better with longer training above\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "yh8GDWMEcKGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export Trained Weights for Future Inference\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ],
      "metadata": {
        "id": "Sk6brwyecsBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "03p4y3_dcKJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0ZKiUDVcu3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TnqkHydocu6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R0DS0f47cu9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TdvabgnUcu_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pQrDLRQXcvCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fbZqxR--cvE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "87H3QoFzcKMe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}